{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pràctica 1 - El procés de l'aprenentatge automàtic:\n",
    "Fins ara hem treballat amb problemes de classificació de conjunts que tenien 2 classes i que estaven generats de manera artificial. En aquesta pràctica començarem a fer feina amb conjunts de dades reals que a més tenen més d'una classe.\n",
    "\n",
    "El procés d'aplicar tècniques d'aprenentatge és un procés que consta de cinc parts:\n",
    "\n",
    "- **Tractament de les dades: preparació del conjunt de dades, selecció de característiques, obtenció dels conjunts d'entrenament / test**.\n",
    "\n",
    "- **Selecció de la / les mètriques adients**.\n",
    "\n",
    "- **Selecció de la tècnica d'aprenentatge automàtic**.\n",
    "\n",
    "- **Avaluació del model**.\n",
    "\n",
    "- **Ajustament del model**.\n",
    "\n",
    "## Tractament de dades: selecció de característiques\n",
    "\n",
    "## Separació del conjunt de dades: validació creuada per avaluar el rendiment del nostre model\n",
    "\n",
    "### Mètode _holdout_\n",
    "\n",
    "Aquest mètode consisteix a separar el conjunt de dades en tres subconjunts diferents: entrenament, validació i _test_. El conjunt d'entrenament s'usa com és habitual, és a dir per entrenar els diferents models. El conjunt de validació s'usa per seleccionar el millor dels models. El conjunt de _test_, que no usem en cap cas durant el procés d'entrenament, ens servirà per obtenir una idea poc esbiaixada de la capacitat del model d'adaptar-se a noves mostres, sobre aquest conjunt de dades serà sobre el qual obtindrem les mètriques finals del model.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "![](imatges/holdout.png)\n",
    "\n",
    "Aquest mètode encara que senzill d'emprar té un desavantatge, el rendiment del model depèn de com hem fet la partició de les dades.\n",
    "\n",
    "### Mètode _K-Fold_\n",
    "\n",
    "Aquesta tècnica és més robusta, ja que repetim el mètode anterior _k_ vegades en _k_ subconjunts del conjunt d'entrenament, per tant, obtenim _k_ models i el mateix nombre de mesures de rendiment. El resultat final s'obtè amb la mitjana de cada una de les repeticions realitzades, d'aquesta manera els resultats depenen manco de les particions que realitzem.\n",
    "\n",
    "Aquesta tècnica normalment s'usa per obtenir els millors paràmetres del model a aplicar, es a dir trobar aquells paràmetres que maximitzen el rendiment de la mètrica que volem usar. Un cop que tenim els millors paràmetres, reentrenam el model emprant el conjunt d'entrenament complet i obtenim les mètriques amb el conjunt de _test_.\n",
    "\n",
    "El procés d'aplicació d'aquesta tècnica es pot veure en el següent gràfic:\n",
    "\n",
    "<img src=\"imatges/Kfold.png\" alt=\"kfold\" width=\"600\"/>\n",
    "\n",
    "La pregunta que ens podem fer és: Com seleccionar aquest paràmetre _k_ de forma correcta?\n",
    "\n",
    "Finalment, existeix una variant d'aquesta tècnica anomenada _stratified k-fold_ en el que les proporcions entre classes es mantenen a cada una de les iteracions, això és important quan tenim problemes desbalancejats.\n",
    "\n",
    "## Selecció de mètriques\n",
    "\n",
    "Un cop entrenat el nostre model, tenim la necessitat d'avaluar els resultats obtinguts amb aquest amb alguna mesura que sigui objectiva. Les mesures que explicarem en aquesta secció es calculen a partir d'una matriu de confusió que ens permet guardar quatre mesures bàsiques a partir de considerar que una de les classes és la positiva i l'altra és la negativa.\n",
    "\n",
    "- _True Positives_ (TP): L'algorisme classifica una mostra de la classe positiva com a membre de la classe positiva.\n",
    "- _True Negatives_ (TN): L'algorisme classifica una mostra de la classe negativa com a membre de la classe negativa.\n",
    "- _False Positives_ (FP): L'algorisme classifica una mostra de la classe negativa com a membre de la classe positiva.\n",
    "- _False Negatives_ (FN): L'algorisme classifica una mostra de la classe positiva com a membre de la classe negativa.\n",
    "\n",
    "Podem observar la matriu de confusió en el següent esquema:\n",
    "\n",
    "![image](imatges/confusion_matrix.png \"font: Python Machine Learning\")\n",
    "\n",
    "Aquesta matriu es pot obtenir de manera senzilla usant la funció `confusion_matrix` de la llibreria [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion%20matrix#sklearn-metrics-confusion-matrix)\n",
    "i es pot visualitzar amb la funció [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html?highlight=confusion%20matrix#sklearn-metrics-confusionmatrixdisplay)\n",
    "\n",
    "A partir d'aquestes mesures de primer ordre en podem treure d'altres més completes com l'error o l'exactitud, també es coneix amb el nom de _Accuracy_.\n",
    "\n",
    "$$ Error = \\frac{FP+FN}{FP+FN+TP+TN}$$\n",
    "<br>\n",
    "$$ Exactitut = \\frac{TP+TN}{FP+FN+TP+TN} = 1 - Error$$\n",
    "\n",
    "Per altra banda, tenim les mesures Rati de Vertaders Positius (_True Positive Rate_, TPR) i la Ratio de Falsos Positius (_False Positive Rate_, FPR) que estan dissenyades per problemes on hi ha una classe amb més mostres que l'altra:\n",
    "\n",
    "$$ FPR = \\frac{FP}{N} = \\frac{FP}{FP+TN} $$\n",
    "<br>\n",
    "$$ TPR = \\frac{TP}{P} = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Finalment, parlarem de precisió (_precision_) i la sensibilitat (_recall_) relacionades amb les ratios de vertaders positius i vertaders negatius:\n",
    "\n",
    "$$ Precisio = \\frac{TP}{TP+FP}$$\n",
    "<br>\n",
    " $$ Sensibilitat = TPR = \\frac{TP}{FN+TP} $$\n",
    "\n",
    "Tenim una mesura que engloba aquestes mesures anteriors:\n",
    "\n",
    "$$ F1 = 2 \\frac{Precisio \\times Sensibilitat}{Precisio + Sensibilitat}$$\n",
    "\n",
    "Per sort tenim un mòdul anomenat [_metrics_](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) on hi ha totes aquestes (i d'altres) mètriques ja implementades.\n",
    "\n",
    "### Qué passa si tenim més de dues classes?\n",
    "\n",
    "Podem generalitzar el que ja sabem per a dues classes a problemes amb tres o més classes, fixem-nos en la imatge següent:\n",
    "\n",
    "![image](imatges/confusion_matrix_multi.png \"font: Researchgate\")\n",
    "\n",
    "Una de les funcions que poden ser més pràctiques en casos multi-classe serà el [classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report).\n",
    "\n",
    "## Un exemple complet\n",
    "\n",
    "A continuació teniu un exemple que resumeix el procés sencer emprant la llibreria `Scikit-learn`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=8, n_redundant=2, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2, class_sep=0.55,\n",
    "                           random_state=5)\n",
    "\n",
    "# Tractament de les dades: Separació i estandaritzat\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenament i predicció, aquí no hi ha ajustament de paràmetres\n",
    "clf = SGDClassifier(loss=\"perceptron\", eta0=0.1, max_iter=500, random_state=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "prediction = clf.predict(X_test_scaled)\n",
    "\n",
    "# Avaluacio\n",
    "cf_matrix = confusion_matrix(y_test, prediction)\n",
    "print(cf_matrix)\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy: \", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-30T15:14:49.761500Z",
     "start_time": "2024-09-30T15:14:49.729845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33 76]\n",
      " [18 73]]\n",
      "Accuracy:  0.53\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Ajustar el model usant una cerca exhaustiva (_Grid Search_)\n",
    "\n",
    "Els paràmetres del nostre model que podem ajustar manualment, es a dir que no són apresos de les dades d'entrenament, s'anomenen hiper-paràmetres. Ajustar el seu valor de manera intuïtiva o mitjançant successions de proves i errors pot ser una tasca llarga, per no dir impossible en el cas de models amb molts paràmetres com poden ser els _Random Forests_. O totes les combinacions possibles de **Kernel** i paràmetres associats.\n",
    "\n",
    "Existeix una tècnica de cerca exhaustiva (provar totes les combinacions de valors possibles) dels valors òptims dels hiper-paràmetres coneguda amb el nom de _Grid Search_ que ens permet automatitzar aquesta cerca penalitzant el cost temporal del procés d'entrenament.\n",
    "\n",
    "\n",
    "## Combinació de _K-Fold_ amb _Grid Search_\n",
    "\n",
    "La combinació de les dues tècniques explicades anteriorment és una de les més emprades, es coneix amb el nom de\n",
    "_nested cross-validation_. En aquest cas tenim dos bucles, un dins l'altra: el més extern en el que es divideix el conjunt\n",
    "d'entrenament usant _K-folding_ i un altre d'intern en el qual es realitza la cerca dels millors hiper-paràmetres.\n",
    "\n",
    "L'esquema que segueix és el següent:\n",
    "\n",
    "<img src=\"imatges/grid_search_k_fold.png\" width=\"600\"/>\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T15:14:59.242123Z",
     "start_time": "2024-09-30T15:14:55.796164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'eta0':[0.001,0.1, 1.0, 0.000001,0.01], 'max_iter':range(5, 5000, 100)}\n",
    "\n",
    "perceptron = SGDClassifier(loss=\"perceptron\", random_state=5)\n",
    "\n",
    "clf = GridSearchCV(perceptron, parameters, cv=3)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "resultats = clf.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "accuracy_score(y_test, resultats)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(eta0=0.001, loss='perceptron', max_iter=5, random_state=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\miniconda3\\envs\\aa_2425\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Resum del procés complet\n",
    "\n",
    "En aquesta pràctica aplicarem l'explicat fins ara usant les eines que _Scikit_ posa al nostre abast. Les passes a seguir són:\n",
    "\n",
    "0. Creació del conjunt de dades: Possibilitat d'extracció de característiques.\n",
    "1. Separació del conjunt de dades: entrenament i test.\n",
    "2. Definició dels paràmetres per ajustar una SVM. El format de la graella de paràmetres és un diccionari on la clau és el nom del paràmetre i el valor una llista amb tots els valors a provar. [Diccionaris a Python](https://docs.python.org/3/tutorial/datastructures.html#dictionaries).\n",
    "3. Aplicar la cerca exhaustiva (_grid search_) juntament amb _k-folding_. Usarem la funció _GridSearchCV_ [enllaç](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV): `GridSearchCV(estimator, param_grid, cv=None, verbose=0)`.\n",
    "4. Entrenar amb el millor model obtingut i el conjunt d'entrenament sencer. Podem obtenir el millor model resultant de la passa anterior amb l'atribut `best_estimator_` de l'objecte `GridSearchCV`. _Nota:_ Si mirau la documentació observareu que podem obtenir altres informacions del procés de la cerca exhaustiva.\n",
    "5. Obtenir els resultats finals amb el conjunt de _test_.\n",
    "\n",
    "# Gatigos: \n",
    "## Classificació d'Imatges de cara de cans i moixos\n",
    "\n",
    "En aquesta pràctica, haureu de desenvolupar un programa en Python que sigui capaç de classificar imatges de cares de cans i moixis utilitzant tècniques d'aprenentatge automàtic. En concret, emprareu un classificador basat en SVM de laa llibreria scikit-learn com el que hem emprat a les pràctiques anteriors.\n",
    "\n",
    "## Instruccions:\n",
    "\n",
    "**Generació de les regions d'interès (ROI)**: Es proporciona un codi que a partir del conjunt d'imatges [Dog and Cat detection](https://www.kaggle.com/datasets/andrewmvd/dog-and-cat-detection) i l'_xml_ associat a cada una d'elles, genera les regions de les cares dels animals (ca i moix) dins les imatges i la seva etiqueta corresponent.\n",
    "\n",
    "**Extracció de característiques amb HoG**: Fes ús de la tècnica Histogram of Oriented Gradients per obtenir un vector de característiques per a cada imatge processada. La llibreria _Skimage_ [enllaç](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.hog) proporciona una funcionalitat per extreure aquestes característiques, també per poder visualitzar-les.\n",
    "\n",
    "**Entrenament del model SVM:** Utilitza la classe SVC de la llibreria scikit-learn per entrenar el model de classificació. Entrena el model amb un conjunt d'imatges d'entrenament de cares de ca i moix. És necessari ajustar adequadament els hiperparàmetres del classificador per optimitzar-ne el rendiment. \n",
    "\n",
    "**Validació i test:** Un cop entrenat el model, valida la precisió del model utilitzant un conjunt d'imatges de test. Presenta els resultats en termes de precisió, sensibilitat, i especificitat.\n",
    "\n",
    "## Requisits:\n",
    "\n",
    "   1. Estudiar HoG. Visualitzar diferents configuracions d'aquest extractor de característiques amb imatges de cans i imatges de moixos, per, d'aquesta manera obtenir una idea de com funciona. \n",
    "   2. S'ha de comparar un SVM lineal emprant els pixels de la imatge com a característiques del classificador amb l'ús dels 3 kernels emprats en les pràctiques anteriors: lineal, polinòmic i gaussià (_RBF_) emprant l'extractor de característiques HoG.\n",
    "   3. S'ha de fer una cerca exhaustiva dels millors paràmetres de cada configuració.\n",
    "   4. S'ha de presentar una taula comparativa dels resultats obtinguts amb un petit conjunt d'imatges de _test_ que s'haurà separat abans de començar el procés. Aquesta taula ha de tenir com a files els diferents experiments i com a columnes les 3 mètriques proposades: precisió, sensibilitat, i F1.\n",
    "   5. S'ha de realitzar una discussió dels resultats obtinguts explicant quins són els millors. Es valorarà que es mostrin imatges que es troben ben i mal classificades per realitzar la discussió. \n",
    "   \n",
    "\n",
    "## Lliurament:\n",
    "\n",
    "   - El codi en un arxiu _.py_ o _.ipynb_ degudament comentat.\n",
    "   - Un informe tècnic en _pdf_ explicant l'estratègia seguida, els resultats obtinguts, i qualsevol dificultat trobada. Aquest informe ha de reflectir les indicacions de la secció anterior.\n",
    "   - Data de lliurament:\n",
    "   - Aquesta pràctica es pot fer de manera individual o en parelles. \n",
    "\n",
    "## Suggeriments:\n",
    "\n",
    "   - Experimenta amb diferents configuracions de la funció HoG i els paràmetres de l’SVC per millorar els resultats.\n",
    "   - Assegura't que el model no sobreentreni i generalitzi bé a imatges noves.\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
